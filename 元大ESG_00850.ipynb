{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>爬取股價與成交量\n",
    "<h5> 標的：00850 元大台灣ESG永續<br>\n",
    "網站：台灣證券交易所"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "#option.add_argument('--headless')\n",
    "option.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "driver = webdriver.Chrome(options=option)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.twse.com.tw/zh/trading/historical/stock-day.html'\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個空的 DataFrame 來存儲合併的資料\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# 使用 tqdm 顯示進度條\n",
    "for i in tqdm(range(1, 13), desc=\"Fetching data for each month\"):\n",
    "    # 點擊年份\n",
    "    driver.find_element(By.CSS_SELECTOR, '#label0').click()\n",
    "    driver.find_element(By.CSS_SELECTOR, '#label0 > option:nth-child(2)').click()\n",
    "\n",
    "    # 點擊月份\n",
    "    driver.find_element(By.CSS_SELECTOR, '#form > div > div.groups > div.group.date-select.M > span > select:nth-child(2)').click()\n",
    "    driver.find_element(By.CSS_SELECTOR, f'#form > div > div.groups > div.group.date-select.M > span > select:nth-child(2) > option:nth-child({i})').click()\n",
    "\n",
    "    sleep(1 + random() * 2)\n",
    "\n",
    "    # 輸入股票代號\n",
    "    driver.find_element(By.CSS_SELECTOR, '#label1').clear()\n",
    "    driver.find_element(By.CSS_SELECTOR, '#label1').send_keys('00850')\n",
    "\n",
    "    # 送出\n",
    "    driver.find_element(By.CSS_SELECTOR, '#form > div > div.groups > div.submit > button').click()\n",
    "\n",
    "    sleep(1 + random() * 2)\n",
    "\n",
    "    # 獲取網頁內容並解析\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    # 獲取標題\n",
    "    headers = [header.text for header in table.find_all('th')]\n",
    "    \n",
    "    # 獲取表格內容\n",
    "    rows = table.find_all('tr')\n",
    "    data = []\n",
    "    for row in rows[1:]:  # 跳過標題行\n",
    "        cols = row.find_all('td')\n",
    "        cols = [col.text.strip() for col in cols]\n",
    "        data.append(cols)\n",
    "    \n",
    "    # 創建當月的 DataFrame\n",
    "    month_df = pd.DataFrame(data, columns=headers)\n",
    "    \n",
    "    # 合併到主 DataFrame\n",
    "    combined_df = pd.concat([combined_df, month_df], ignore_index=True)\n",
    "\n",
    "# 顯示結果\n",
    "print(combined_df)\n",
    "\n",
    "# 保存合併後的資料到新檔案\n",
    "combined_df.to_csv('/Users/lomingyi/Downloads/期末專案/00850/00850股價資訊_2023.csv', index=False)\n",
    "\n",
    "# 關閉瀏覽器\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>爬取 漲跌幅 資料\n",
    "<h5>進入以下網址，往下滑到漲跌幅表格，匯出後手動刪除不必要的欄位<br>\n",
    "https://goodinfo.tw/tw/ShowK_ChartCompare.asp?STOCK_ID=00850&STOCK_ID1="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>爬取 Google Trend 資料\n",
    "<h5>用 API（pytrend）很容易會被 google trend 限制存取，導致沒辦法抓到資料。<br>\n",
    "所以最後改用手動輸入並下載<br>\n",
    "網址：https://trends.google.com.tw/trends?geo=TW&hl=zh-TW\n",
    "\n",
    "關鍵詞：AI、chatgpt、輝達、台積電"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>爬取 三大法人 資料\n",
    "<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from random import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "header = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "#option.add_argument('--headless')\n",
    "option.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "driver = webdriver.Chrome(options=option)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.twse.com.tw/zh/trading/foreign/t86.html'\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建一個空的 DataFrame 並設置 headers\n",
    "headers = []  # 初始化 headers 列表\n",
    "\n",
    "# 使用 tqdm 顯示進度條\n",
    "for i in tqdm(range(1, 13), desc=\"Fetching data for each month\"):\n",
    "    for j in tqdm(range(1, 32), desc=\"Fetching data for each day\"):\n",
    "        try:\n",
    "            # 點擊年份\n",
    "            driver.find_element(By.CSS_SELECTOR, '#label0').click()\n",
    "            driver.find_element(By.CSS_SELECTOR, '#label0 > option:nth-child(2)').click()\n",
    "            # 點擊月份\n",
    "            driver.find_element(By.CSS_SELECTOR, '#form > div > div.groups > div.group.date-select.D > span > select:nth-child(2)').click()\n",
    "            driver.find_element(By.CSS_SELECTOR, f'#form > div > div.groups > div.group.date-select.D > span > select:nth-child(2) > option:nth-child({i})').click()\n",
    "            # 點擊日期\n",
    "            driver.find_element(By.CSS_SELECTOR, '#form > div > div.groups > div.group.date-select.D > span > select:nth-child(3)').click()\n",
    "            driver.find_element(By.CSS_SELECTOR, f'#form > div > div.groups > div.group.date-select.D > span > select:nth-child(3) > option:nth-child({j})').click()\n",
    "            # 點擊查詢\n",
    "            driver.find_element(By.CSS_SELECTOR, '#form > div > div.groups > div.submit > button').click()\n",
    "            # 點擊類別\n",
    "            driver.find_element(By.CSS_SELECTOR, '#label1').click()\n",
    "            driver.find_element(By.CSS_SELECTOR, '#label1 > option:nth-child(4)').click()\n",
    "\n",
    "            sleep(0.5 + random() * 2)\n",
    "\n",
    "            # 檢查表格是否存在\n",
    "            try:\n",
    "                message = driver.find_element(By.CSS_SELECTOR, '#reports > div.main-content > div.rwd-table.dragscroll.sortable.F2.R3_.active > div').text\n",
    "                if \"很抱歉，沒有符合條件的資料!\" in message:\n",
    "                    print(f\"No data for {i}-{j}\")\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # 選取顯示全部\n",
    "            driver.find_element(By.CSS_SELECTOR, '#reports > hgroup > div > div.per-page > select').click()\n",
    "            driver.find_element(By.CSS_SELECTOR, '#reports > hgroup > div > div.per-page > select > option:nth-child(5)').click()\n",
    "\n",
    "            # 獲取網頁內容並解析\n",
    "            sleep(1)  # 等待頁面加載\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            table = soup.find('table')\n",
    "\n",
    "            if table:\n",
    "                # 如果 headers 還沒有建立在 df 中，就先抓下來並建立\n",
    "                if not headers:\n",
    "                    header_elements = table.find_all('th')[2:]  # 從第三個 column 開始，因為前兩個是代號和名稱\n",
    "                    headers = ['日期'] + [header.text.strip() for header in header_elements]  # 添加 '日期' 列\n",
    "                    combined_df = pd.DataFrame(columns=headers)\n",
    "\n",
    "                rows = table.find_all('tr')\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    if len(cols) > 0 and cols[0].text.strip() == '00850':\n",
    "                        print(f'{i}-{j} success!')\n",
    "                        data = [f'{i}-{j}'] + [col.text.strip() for col in cols[2:]] \n",
    "                        if len(data) == len(headers):  # 確保 data 和 headers 的長度一致\n",
    "                            temp_df = pd.DataFrame([data], columns=headers)\n",
    "                            combined_df = pd.concat([combined_df, temp_df], ignore_index=True)\n",
    "                        else:\n",
    "                            print(f\"Data length mismatch: {len(data)} vs {len(headers)}\")\n",
    "                        break  # 找到目標資料後跳出循環\n",
    "\n",
    "            # 添加延遲以避免被封鎖\n",
    "            sleep(0.5 + random() * 2)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred on {i}-{j}: {e}\")\n",
    "            continue\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# 保存合併後的資料到 CSV 文件\n",
    "combined_df.to_csv('/Users/lomingyi/Downloads/期末專案/00850/00850三大法人資訊_2023.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>爬取 大盤指數 資料\n",
    "<h5>目前先爬取「加權指數」、「NASDAQ」、「S&P500」、「」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加權指數\n",
    "import yfinance as yf\n",
    "\n",
    "data = yf.download('^TWII', start='2023-01-01', end='2023-12-31')\n",
    "data.to_csv('/Users/lomingyi/Downloads/期末專案/加權指數_2023.csv')\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NASDAQ\n",
    "import yfinance as yf\n",
    "\n",
    "data = yf.download('^IXIC', start='2023-01-01', end='2023-12-31')\n",
    "data.to_csv('/Users/lomingyi/Downloads/期末專案/NASDAQ_2023.csv')\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S&P 500\n",
    "import yfinance as yf\n",
    "\n",
    "data = yf.download('^GSPC', start='2023-01-01', end='2023-12-31')\n",
    "data.to_csv('/Users/lomingyi/Downloads/期末專案/SP500_2023.csv')\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dow Jones Industrial Average\n",
    "import yfinance as yf\n",
    "\n",
    "data = yf.download('^DJI', start='2023-01-01', end='2023-12-31')\n",
    "data.to_csv('/Users/lomingyi/Downloads/期末專案/dowjones_2023.csv')\n",
    "print('success!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
