{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>讀取所有資料\n",
    "<h5> 讀取漲跌幅、google trend、成交量、指數、淨值、三大法人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 漲跌幅\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/00850漲跌幅資訊_2023.csv'\n",
    "price_df = pd.read_csv(file_path)\n",
    "\n",
    "# Google Trend\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/00850 Google Trend_2023.csv'\n",
    "trend_df = pd.read_csv(file_path)\n",
    "\n",
    "# 成交量\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/00850股價資訊_2023.csv'\n",
    "volume_df = pd.read_csv(file_path)\n",
    "\n",
    "# 指數1 - 大盤\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/Index/加權指數_2023.csv'\n",
    "index_TW_df = pd.read_csv(file_path)\n",
    "\n",
    "# 指數2 - NASDAQ\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/Index/NASDAQ_2023.csv'\n",
    "index_NASDAQ_df = pd.read_csv(file_path)\n",
    "\n",
    "# 指數3 - 道瓊\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/Index/dowjones_2023.csv'\n",
    "index_DOW_df = pd.read_csv(file_path)\n",
    "\n",
    "# 指數4 - S&P\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/Index/SP500_2023.csv'\n",
    "index_SP_df = pd.read_csv(file_path)\n",
    "\n",
    "# 淨值\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/00850_nav.csv'\n",
    "nav_df = pd.read_csv(file_path)\n",
    "\n",
    "# 三大法人\n",
    "file_path = '/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/00850三大法人資訊_2023.csv'\n",
    "institution_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>清理＆處理資料\n",
    "<h5> 先處理漲跌幅資料<br>\n",
    "1. 只保留df中的交易日期和漲跌幅這兩個欄位<br>\n",
    "2. 將交易日期的格式改為python中的時間格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep only the '交易日期' and '漲跌幅' columns\n",
    "price_df = price_df[['交易日期', '漲跌幅']]\n",
    "\n",
    "# 2. Convert '交易日期' to datetime format\n",
    "price_df['交易日期'] = pd.to_datetime(price_df['交易日期'].str.replace(\"'\", \"\"), format='%y/%m/%d')\n",
    "\n",
    "price_df = price_df.rename(columns={'交易日期': '日期'})\n",
    "\n",
    "# Sort price_df by '日期'\n",
    "price_df = price_df.sort_values(by='日期').reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(price_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 處理成交量<br>\n",
    "1. 只保留df中的日期和成交股數和成交筆數這三個欄位<br>\n",
    "2. 將交易日期的格式改為python中的時間格式<br>\n",
    "3. 計算大戶與散戶比例：股數/筆數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to convert ROC year to AD year\n",
    "def convert_roc_to_ad(date_str):\n",
    "    year, month, day = date_str.split('/')\n",
    "    ad_year = int(year) + 1911\n",
    "    return f'{ad_year}/{month}/{day}'\n",
    "\n",
    "# 1. Keep only the '日期', '成交股數', and '成交筆數' columns\n",
    "volume_df = volume_df[['日期', '成交股數', '成交筆數']]\n",
    "\n",
    "# Apply the conversion function to the '日期' column\n",
    "volume_df['日期'] = volume_df['日期'].apply(convert_roc_to_ad)\n",
    "\n",
    "# Convert '日期' to datetime format\n",
    "volume_df['日期'] = pd.to_datetime(volume_df['日期'], format='%Y/%m/%d')\n",
    "\n",
    "# Remove commas from '成交股數' and '成交筆數', then convert to integers\n",
    "volume_df['成交股數'] = volume_df['成交股數'].str.replace(',', '').astype(int)\n",
    "volume_df['成交筆數'] = volume_df['成交筆數'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Add a new column '大戶與散戶比例' calculated as '成交股數' / '成交筆數'\n",
    "volume_df['大戶與散戶比例'] = volume_df['成交股數'] / volume_df['成交筆數']\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(volume_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 處理指數資料<br>\n",
    "1. 只保留df中的Date, Close, Volume 這三個欄位<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TW\n",
    "index_TW_df = index_TW_df[['Date', 'Close', 'Volume']]\n",
    "index_TW_df = index_TW_df.rename(columns={'Date': '日期'})\n",
    "index_TW_df['日期'] = pd.to_datetime(index_TW_df['日期'], format='%Y-%m-%d')\n",
    "print(index_TW_df.head())\n",
    "\n",
    "# NASDAQ\n",
    "index_NASDAQ_df = index_NASDAQ_df[['Date', 'Close', 'Volume']]\n",
    "index_NASDAQ_df = index_NASDAQ_df.rename(columns={'Date': '日期'})\n",
    "index_NASDAQ_df['日期'] = pd.to_datetime(index_NASDAQ_df['日期'], format='%Y-%m-%d')\n",
    "print(index_NASDAQ_df.head())\n",
    "\n",
    "# DOW\n",
    "index_DOW_df = index_DOW_df[['Date', 'Close', 'Volume']]\n",
    "index_DOW_df = index_DOW_df.rename(columns={'Date': '日期'})\n",
    "index_DOW_df['日期'] = pd.to_datetime(index_DOW_df['日期'], format='%Y-%m-%d')\n",
    "print(index_DOW_df.head())\n",
    "\n",
    "# SP\n",
    "index_SP_df = index_SP_df[['Date', 'Close', 'Volume']]\n",
    "index_SP_df = index_SP_df.rename(columns={'Date': '日期'})\n",
    "index_SP_df['日期'] = pd.to_datetime(index_SP_df['日期'], format='%Y-%m-%d')\n",
    "print(index_SP_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 處理淨值資料<br>\n",
    "1. 將交易日期的格式改為python中的時間格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nav_df['年月日'] = pd.to_datetime(nav_df['年月日'], format='%Y/%m/%d')\n",
    "nav_df = nav_df.rename(columns={'年月日': '日期'})\n",
    "\n",
    "# Sort nav_df by '日期'\n",
    "nav_df = nav_df.sort_values(by='日期').reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(nav_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 處理三大法人資料<br>\n",
    "1. 留下「日期」、「外陸資買賣超股數(不含外資自營商)」、「投信買賣超股數」、「自營商買賣超股數」四個欄位<br>\n",
    "2. 將交易日期的格式改為python中的時間格式<br>\n",
    "3. 將資料都改成數字格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep only the relevant columns\n",
    "institution_df = institution_df[['日期', '外陸資買賣超股數(不含外資自營商)', '投信買賣超股數', '自營商買賣超股數']]\n",
    "\n",
    "# 2. Convert '日期' to datetime format, assuming all dates are in 2023\n",
    "institution_df['日期'] = pd.to_datetime('2023-' + institution_df['日期'], format='%Y-%m-%d')\n",
    "\n",
    "# 3. Change data into numeric format\n",
    "columns_to_convert = ['外陸資買賣超股數(不含外資自營商)', '投信買賣超股數', '自營商買賣超股數']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    institution_df[column] = institution_df[column].astype(str).str.replace(',', '')\n",
    "    institution_df[column] = pd.to_numeric(institution_df[column])\n",
    "\n",
    "institution_df.rename(columns={'外陸資買賣超股數(不含外資自營商)': '三大法人：外陸資買賣超股數(不含外資自營商)', '投信買賣超股數': '三大法人：投信買賣超股數', '自營商買賣超股數': '三大法人：自營商買賣超股數'}, inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(institution_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> 處理 Google Trend 資料<br>\n",
    "因為現在是以周為單位，使用平均分攤的方式讓每一天都有數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the '週' column as datetime\n",
    "trend_df['週'] = pd.to_datetime(trend_df['週'])\n",
    "\n",
    "# Set '週' column as the index\n",
    "trend_df.set_index('週', inplace=True)\n",
    "\n",
    "# Create a date range from the start to the end date\n",
    "date_range = pd.date_range(start=trend_df.index.min(), end=trend_df.index.max(), freq='D')\n",
    "\n",
    "# Reindex the DataFrame to include all dates in the range\n",
    "trend_df = trend_df.reindex(date_range)\n",
    "\n",
    "# Interpolate the missing values\n",
    "trend_df = trend_df.interpolate(method='linear')\n",
    "\n",
    "# Reset index to have '日期' as a column again\n",
    "trend_df.reset_index(inplace=True)\n",
    "trend_df.rename(columns={'index': '日期', 'ESG': '聲量：ESG', '永續': '聲量：永續', '環保': '聲量：環保'}, inplace=True)\n",
    "\n",
    "# Display the first few rows to verify the changes\n",
    "print(trend_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>資料串接（4-6月）\n",
    "<h5> 把所有資料串接在一起，並且漲跌幅（＄）要往未來平移一天，才能確保是在預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 漲跌幅\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for data from 2023-04-01 to 2023-06-30\n",
    "filtered_price_df = price_df[(price_df['日期'] >= '2023-04-01') & (price_df['日期'] <= '2023-06-30')]\n",
    "\n",
    "# Create the 456_df with '日期' and '漲跌幅' columns from filtered_price_df\n",
    "df_456 = filtered_price_df[['日期', '漲跌幅']].reset_index(drop=True)\n",
    "\n",
    "# Display the 456_df\n",
    "print(df_456.head())\n",
    "print(df_456.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Trend\n",
    "# Filter the trend_df to match the date range of df_456\n",
    "filtered_trend_df = trend_df[(trend_df['日期'] >= '2023-04-01') & (trend_df['日期'] <= '2023-06-30')]\n",
    "\n",
    "# Merge trend_df data into df_456\n",
    "df_456 = pd.merge(df_456, filtered_trend_df[['日期', '聲量：ESG', '聲量：永續', '聲量：環保']], on='日期', how='left')\n",
    "\n",
    "# Display the resulting df_456\n",
    "print(df_456.head())\n",
    "print(df_456.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 成交量\n",
    "# Filter the trend_df to match the date range of df_456\n",
    "filtered_volume_df = volume_df[(volume_df['日期'] >= '2023-04-01') & (volume_df['日期'] <= '2023-06-30')]\n",
    "\n",
    "# Merge trend_df data into df_456\n",
    "df_456 = pd.merge(df_456, filtered_volume_df[['日期', '成交股數', '成交筆數', '大戶與散戶比例']], on='日期', how='left')\n",
    "\n",
    "# Display the resulting df_456\n",
    "print(df_456.head())\n",
    "print(df_456.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指數\n",
    "# Function to fill missing values with the average of the nearest two dates' values\n",
    "def fill_missing_values(row, df, column_name):\n",
    "    if pd.isnull(row[column_name]):\n",
    "        closest_dates = df['日期'].sub(row['日期']).abs().sort_values().index[:2]\n",
    "        row[column_name] = df.loc[closest_dates, column_name].mean()\n",
    "    return row\n",
    "\n",
    "# TW\n",
    "filtered_index_TW_df = index_TW_df[(index_TW_df['日期'] >= '2023-04-01') & (index_TW_df['日期'] <= '2023-06-30')]\n",
    "df_456 = pd.merge(df_456, filtered_index_TW_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_456.rename(columns={'Close': '指數：TW_Close', 'Volume': '指數：TW_Volume'}, inplace=True)\n",
    "\n",
    "# NASDAQ\n",
    "filtered_index_NASDAQ_df = index_NASDAQ_df[(index_NASDAQ_df['日期'] >= '2023-04-01') & (index_NASDAQ_df['日期'] <= '2023-06-30')]\n",
    "df_456 = pd.merge(df_456, filtered_index_NASDAQ_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_456.rename(columns={'Close': '指數：NASDAQ_Close', 'Volume': '指數：NASDAQ_Volume'}, inplace=True)\n",
    "# 填補缺失值\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=df_456, column_name='指數：NASDAQ_Close')\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=df_456, column_name='指數：NASDAQ_Volume')\n",
    "\n",
    "# DOW JONES\n",
    "filtered_index_DOW_df = index_DOW_df[(index_DOW_df['日期'] >= '2023-04-01') & (index_DOW_df['日期'] <= '2023-06-30')]\n",
    "df_456 = pd.merge(df_456, filtered_index_DOW_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_456.rename(columns={'Close': '指數：DOW_Close', 'Volume': '指數：DOW_Volume'}, inplace=True)\n",
    "# 填補缺失值\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=df_456, column_name='指數：DOW_Close')\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=df_456, column_name='指數：DOW_Volume')\n",
    "\n",
    "# S&P500\n",
    "filtered_index_SP_df = index_SP_df[(index_SP_df['日期'] >= '2023-04-01') & (index_SP_df['日期'] <= '2023-06-30')]\n",
    "df_456 = pd.merge(df_456, filtered_index_SP_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_456.rename(columns={'Close': '指數：SP_Close', 'Volume': '指數：SP_Volume'}, inplace=True)\n",
    "# 填補缺失值\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=df_456, column_name='指數：SP_Close')\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=df_456, column_name='指數：SP_Volume')\n",
    "\n",
    "# Display the resulting df_456\n",
    "print(df_456.head())\n",
    "print(df_456.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三大法人\n",
    "filtered_institution_df = institution_df[(institution_df['日期'] >= '2023-04-01') & (institution_df['日期'] <= '2023-06-30')]\n",
    "df_456 = pd.merge(df_456, filtered_institution_df[['日期', '三大法人：外陸資買賣超股數(不含外資自營商)', '三大法人：投信買賣超股數', '三大法人：自營商買賣超股數']], on='日期', how='left')\n",
    "\n",
    "# 填補缺失值\n",
    "df_456 = df_456.fillna(0)\n",
    "\n",
    "# Display the resulting df_456\n",
    "print(df_456.head())\n",
    "print(df_456.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 淨值\n",
    "filtered_nav_df = nav_df[(nav_df['日期'] >= '2023-04-01') & (nav_df['日期'] <= '2023-06-30')]\n",
    "\n",
    "# Merge nav_df data into df_456\n",
    "df_456 = pd.merge(df_456, filtered_nav_df[['日期', '淨值(元)']], on='日期', how='left')\n",
    "\n",
    "# Function to fill missing values with the average of the nearest two dates' values\n",
    "def fill_missing_values(row, df, column_name):\n",
    "    if pd.isnull(row[column_name]):\n",
    "        closest_dates = df['日期'].sub(row['日期']).abs().sort_values().index[:2]\n",
    "        row[column_name] = df.loc[closest_dates, column_name].mean()\n",
    "    return row\n",
    "\n",
    "# Apply the function to fill missing NAV values\n",
    "df_456 = df_456.apply(fill_missing_values, axis=1, df=nav_df, column_name='淨值(元)')\n",
    "\n",
    "# Display the resulting df_456\n",
    "print(df_456.head())\n",
    "print(df_456.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 漲跌幅（＄）要往未來平移一天，才能確保是在預測\n",
    "\n",
    "# Remove the first row from '漲跌幅' column and reindex it\n",
    "df_456['漲跌幅'] = df_456['漲跌幅'].shift(-1)\n",
    "\n",
    "# Remove the last row\n",
    "df_456 = df_456.iloc[:-1]\n",
    "\n",
    "# Drop rows where '漲跌幅' is NaN (which would only be the last row now)\n",
    "df_456 = df_456.dropna(subset=['漲跌幅'])\n",
    "\n",
    "# Convert \"漲跌幅\" column to numeric\n",
    "df_456['漲跌幅'] = df_456['漲跌幅'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "df_456 = df_456.drop(\"日期\", axis = 1)\n",
    "\n",
    "# Display the resulting df_456\n",
    "print(df_456.head())\n",
    "print(df_456.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存檔備份\n",
    "df_456.to_csv(\"/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_456.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>資料分析\n",
    "<h5> 分別分析 5、7、10 天為區間，漲跌幅與各個指標的相關性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 5 天為群組\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame for storing correlations\n",
    "columns_456 = df_456.columns\n",
    "df_456_5day_corr = pd.DataFrame(columns=columns_456[1:])\n",
    "\n",
    "# Define a function to calculate correlations\n",
    "def calculate_correlations(df, corr_df, group_size):\n",
    "    n_rows = df.shape[0]\n",
    "    for i in range(0, n_rows, group_size):\n",
    "        df_group = df.iloc[i:i + group_size]\n",
    "        if df_group.shape[0] == group_size:  # 如果最後不足最少天數，就不分析\n",
    "            corr = df_group.corr()\n",
    "            first_row = corr.iloc[0]\n",
    "            first_row_df = pd.DataFrame(first_row).T\n",
    "            corr_df = pd.concat([corr_df, first_row_df], ignore_index=True)\n",
    "    return corr_df\n",
    "\n",
    "# Calculate correlations for \"AI\" column\n",
    "df_456_5day_corr = calculate_correlations(df_456, df_456_5day_corr, 5)\n",
    "\n",
    "# 空值補0\n",
    "df_456_5day_corr = df_456_5day_corr.fillna(0)\n",
    "\n",
    "# Drop \"漲跌幅\" column\n",
    "df_456_5day_corr = df_456_5day_corr.drop(columns=['漲跌幅'], errors='ignore')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df_456_5day_corr.to_csv('/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_456_5day_corr.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df_456_5day_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 7 天為群組\n",
    "\n",
    "# Create an empty DataFrame for storing correlations\n",
    "columns_456 = df_456.columns\n",
    "df_456_7day_corr = pd.DataFrame(columns=columns_456[1:])\n",
    "\n",
    "# Define a function to calculate correlations\n",
    "def calculate_correlations(df, corr_df, group_size):\n",
    "    n_rows = df.shape[0]\n",
    "    for i in range(0, n_rows, group_size):\n",
    "        df_group = df.iloc[i:i + group_size]\n",
    "        if df_group.shape[0] == group_size:  # 如果最後不足最少天數，就不分析\n",
    "            corr = df_group.corr()\n",
    "            first_row = corr.iloc[0]\n",
    "            first_row_df = pd.DataFrame(first_row).T\n",
    "            corr_df = pd.concat([corr_df, first_row_df], ignore_index=True)\n",
    "    return corr_df\n",
    "\n",
    "# Calculate correlations for \"AI\" column\n",
    "df_456_7day_corr = calculate_correlations(df_456, df_456_7day_corr, 7)\n",
    "\n",
    "# 空值補0\n",
    "df_456_7day_corr = df_456_7day_corr.fillna(0)\n",
    "\n",
    "# Drop \"漲跌幅\" column\n",
    "df_456_7day_corr = df_456_7day_corr.drop(columns=['漲跌幅'], errors='ignore')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df_456_7day_corr.to_csv('/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_456_7day_corr.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df_456_7day_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 10 天為群組\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame for storing correlations\n",
    "columns_456 = df_456.columns\n",
    "df_456_10day_corr = pd.DataFrame(columns=columns_456[1:])\n",
    "\n",
    "# Define a function to calculate correlations\n",
    "def calculate_correlations(df, corr_df, group_size):\n",
    "    n_rows = df.shape[0]\n",
    "    for i in range(0, n_rows, group_size):\n",
    "        df_group = df.iloc[i:i + group_size]\n",
    "        if df_group.shape[0] == group_size:  # 如果最後不足最少天數，就不分析\n",
    "            corr = df_group.corr()\n",
    "            first_row = corr.iloc[0]\n",
    "            first_row_df = pd.DataFrame(first_row).T\n",
    "            corr_df = pd.concat([corr_df, first_row_df], ignore_index=True)\n",
    "    return corr_df\n",
    "\n",
    "# Calculate correlations for \"AI\" column\n",
    "df_456_10day_corr = calculate_correlations(df_456, df_456_10day_corr, 10)\n",
    "\n",
    "# 空值補0\n",
    "df_456_10day_corr = df_456_10day_corr.fillna(0)\n",
    "\n",
    "# Drop \"漲跌幅\" column\n",
    "df_456_10day_corr = df_456_10day_corr.drop(columns=['漲跌幅'], errors='ignore')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df_456_10day_corr.to_csv('/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_456_10day_corr.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df_456_10day_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>資料串接（10-12月）\n",
    "<h5> 把所有資料串接在一起，並且漲跌幅（＄）要往未來平移一天，才能確保是在預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 漲跌幅\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for data from 2023-10-01 to 2023-12-31\n",
    "filtered_price_df = price_df[(price_df['日期'] >= '2023-10-01') & (price_df['日期'] <= '2023-12-31')]\n",
    "\n",
    "# Create the df_101112 with '日期' and '漲跌幅' columns from filtered_price_df\n",
    "df_101112 = filtered_price_df[['日期', '漲跌幅']].reset_index(drop=True)\n",
    "\n",
    "# Display the df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Trend\n",
    "# Filter the trend_df to match the date range of df_101112\n",
    "filtered_trend_df = trend_df[(trend_df['日期'] >= '2023-10-01') & (trend_df['日期'] <= '2023-12-31')]\n",
    "\n",
    "# Merge trend_df data into df_101112\n",
    "df_101112 = pd.merge(df_101112, filtered_trend_df[['日期', '聲量：AI', '聲量：CHATGPT', '聲量：輝達', '聲量：台積電']], on='日期', how='left')\n",
    "\n",
    "# Display the resulting df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 成交量\n",
    "# Filter the trend_df to match the date range of df_101112\n",
    "filtered_volume_df = volume_df[(volume_df['日期'] >= '2023-10-01') & (volume_df['日期'] <= '2023-12-31')]\n",
    "\n",
    "# Merge trend_df data into df_101112\n",
    "df_101112 = pd.merge(df_101112, filtered_volume_df[['日期', '成交股數', '成交筆數', '大戶與散戶比例']], on='日期', how='left')\n",
    "\n",
    "# Display the resulting df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指數\n",
    "# Function to fill missing values with the average of the nearest two dates' values\n",
    "def fill_missing_values(row, df, column_name):\n",
    "    if pd.isnull(row[column_name]):\n",
    "        closest_dates = df['日期'].sub(row['日期']).abs().sort_values().index[:2]\n",
    "        row[column_name] = df.loc[closest_dates, column_name].mean()\n",
    "    return row\n",
    "\n",
    "# TW\n",
    "filtered_index_TW_df = index_TW_df[(index_TW_df['日期'] >= '2023-10-01') & (index_TW_df['日期'] <= '2023-12-31')]\n",
    "df_101112 = pd.merge(df_101112, filtered_index_TW_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_101112.rename(columns={'Close': '指數：TW_Close', 'Volume': '指數：TW_Volume'}, inplace=True)\n",
    "\n",
    "# NASDAQ\n",
    "filtered_index_NASDAQ_df = index_NASDAQ_df[(index_NASDAQ_df['日期'] >= '2023-10-01') & (index_NASDAQ_df['日期'] <= '2023-12-31')]\n",
    "df_101112 = pd.merge(df_101112, filtered_index_NASDAQ_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_101112.rename(columns={'Close': '指數：NASDAQ_Close', 'Volume': '指數：NASDAQ_Volume'}, inplace=True)\n",
    "# 填補缺失值\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=df_101112, column_name='指數：NASDAQ_Close')\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=df_101112, column_name='指數：NASDAQ_Volume')\n",
    "\n",
    "# DOW JONES\n",
    "filtered_index_DOW_df = index_DOW_df[(index_DOW_df['日期'] >= '2023-10-01') & (index_DOW_df['日期'] <= '2023-12-31')]\n",
    "df_101112 = pd.merge(df_101112, filtered_index_DOW_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_101112.rename(columns={'Close': '指數：DOW_Close', 'Volume': '指數：DOW_Volume'}, inplace=True)\n",
    "# 填補缺失值\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=df_101112, column_name='指數：DOW_Close')\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=df_101112, column_name='指數：DOW_Volume')\n",
    "\n",
    "# S&P500\n",
    "filtered_index_SP_df = index_SP_df[(index_SP_df['日期'] >= '2023-10-01') & (index_SP_df['日期'] <= '2023-12-31')]\n",
    "df_101112 = pd.merge(df_101112, filtered_index_SP_df[['日期', 'Close', 'Volume']], on='日期', how='left')\n",
    "df_101112.rename(columns={'Close': '指數：SP_Close', 'Volume': '指數：SP_Volume'}, inplace=True)\n",
    "# 填補缺失值\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=df_101112, column_name='指數：SP_Close')\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=df_101112, column_name='指數：SP_Volume')\n",
    "\n",
    "# Display the resulting df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三大法人\n",
    "filtered_institution_df = institution_df[(institution_df['日期'] >= '2023-10-01') & (institution_df['日期'] <= '2023-12-31')]\n",
    "df_101112 = pd.merge(df_101112, filtered_institution_df[['日期', '三大法人：外陸資買賣超股數(不含外資自營商)', '三大法人：投信買賣超股數', '三大法人：自營商買賣超股數']], on='日期', how='left')\n",
    "\n",
    "# 填補缺失值\n",
    "df_101112 = df_101112.fillna(0)\n",
    "\n",
    "# Display the resulting df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 淨值\n",
    "filtered_nav_df = nav_df[(nav_df['日期'] >= '2023-10-01') & (nav_df['日期'] <= '2023-12-31')]\n",
    "\n",
    "# Merge nav_df data into df_101112\n",
    "df_101112 = pd.merge(df_101112, filtered_nav_df[['日期', '淨值(元)']], on='日期', how='left')\n",
    "\n",
    "# Function to fill missing values with the average of the nearest two dates' values\n",
    "def fill_missing_values(row, df, column_name):\n",
    "    if pd.isnull(row[column_name]):\n",
    "        closest_dates = df['日期'].sub(row['日期']).abs().sort_values().index[:2]\n",
    "        row[column_name] = df.loc[closest_dates, column_name].mean()\n",
    "    return row\n",
    "\n",
    "# Apply the function to fill missing NAV values\n",
    "df_101112 = df_101112.apply(fill_missing_values, axis=1, df=nav_df, column_name='淨值(元)')\n",
    "\n",
    "# Display the resulting df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 漲跌幅（＄）要往未來平移一天，才能確保是在預測\n",
    "\n",
    "# Remove the first row from '漲跌幅' column and reindex it\n",
    "df_101112['漲跌幅'] = df_101112['漲跌幅'].shift(-1)\n",
    "\n",
    "# Remove the last row\n",
    "df_101112 = df_101112.iloc[:-1]\n",
    "\n",
    "# Drop rows where '漲跌幅' is NaN (which would only be the last row now)\n",
    "df_101112 = df_101112.dropna(subset=['漲跌幅'])\n",
    "\n",
    "# Convert \"漲跌幅\" column to numeric\n",
    "df_101112['漲跌幅'] = df_101112['漲跌幅'].str.replace('%', '').astype(float) / 100\n",
    "\n",
    "df_101112 = df_101112.drop(\"日期\", axis = 1)\n",
    "\n",
    "# Display the resulting df_101112\n",
    "print(df_101112.head())\n",
    "print(df_101112.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存檔備份\n",
    "df_101112.to_csv(\"/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_101112.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>資料分析\n",
    "<h5> 分別分析 5、7、10 天為區間，漲跌幅與各個指標的相關性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 5 天為群組\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame for storing correlations\n",
    "columns_101112 = df_101112.columns\n",
    "df_101112_5day_corr = pd.DataFrame(columns=columns_101112[1:])\n",
    "\n",
    "# Define a function to calculate correlations\n",
    "def calculate_correlations(df, corr_df, group_size):\n",
    "    n_rows = df.shape[0]\n",
    "    for i in range(0, n_rows, group_size):\n",
    "        df_group = df.iloc[i:i + group_size]\n",
    "        if df_group.shape[0] == group_size:  # 如果最後不足最少天數，就不分析\n",
    "            corr = df_group.corr()\n",
    "            print(corr)\n",
    "            first_row = corr.iloc[0]\n",
    "            first_row_df = pd.DataFrame(first_row).T\n",
    "            corr_df = pd.concat([corr_df, first_row_df], ignore_index=True)\n",
    "    return corr_df\n",
    "\n",
    "# Calculate correlations\n",
    "df_101112_5day_corr = calculate_correlations(df_101112, df_101112_5day_corr, 5)\n",
    "\n",
    "# 空值補0\n",
    "df_101112_5day_corr = df_101112_5day_corr.fillna(0)\n",
    "\n",
    "# Drop \"漲跌幅\" column\n",
    "df_101112_5day_corr = df_101112_5day_corr.drop(columns=['漲跌幅'], errors='ignore')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df_101112_5day_corr.to_csv('/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_101112_5day_corr.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df_101112_5day_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 7 天為群組\n",
    "\n",
    "# Create an empty DataFrame for storing correlations\n",
    "columns_101112 = df_101112.columns\n",
    "df_101112_7day_corr = pd.DataFrame(columns=columns_101112[1:])\n",
    "\n",
    "# Define a function to calculate correlations\n",
    "def calculate_correlations(df, corr_df, group_size):\n",
    "    n_rows = df.shape[0]\n",
    "    for i in range(0, n_rows, group_size):\n",
    "        df_group = df.iloc[i:i + group_size]\n",
    "        if df_group.shape[0] == group_size:  # 如果最後不足最少天數，就不分析\n",
    "            corr = df_group.corr()\n",
    "            first_row = corr.iloc[0]\n",
    "            first_row_df = pd.DataFrame(first_row).T\n",
    "            corr_df = pd.concat([corr_df, first_row_df], ignore_index=True)\n",
    "    return corr_df\n",
    "\n",
    "# Calculate correlations for \"AI\" column\n",
    "df_101112_7day_corr = calculate_correlations(df_101112, df_101112_7day_corr, 7)\n",
    "\n",
    "# 空值補0\n",
    "df_101112_7day_corr = df_101112_7day_corr.fillna(0)\n",
    "\n",
    "# Drop \"漲跌幅\" column\n",
    "df_101112_7day_corr = df_101112_7day_corr.drop(columns=['漲跌幅'], errors='ignore')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df_101112_7day_corr.to_csv('/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_101112_7day_corr.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df_101112_7day_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 10 天為群組\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame for storing correlations\n",
    "columns_101112 = df_101112.columns\n",
    "df_101112_10day_corr = pd.DataFrame(columns=columns_101112[1:])\n",
    "\n",
    "# Define a function to calculate correlations\n",
    "def calculate_correlations(df, corr_df, group_size):\n",
    "    n_rows = df.shape[0]\n",
    "    for i in range(0, n_rows, group_size):\n",
    "        df_group = df.iloc[i:i + group_size]\n",
    "        if df_group.shape[0] == group_size:  # 如果最後不足最少天數，就不分析\n",
    "            corr = df_group.corr()\n",
    "            first_row = corr.iloc[0]\n",
    "            first_row_df = pd.DataFrame(first_row).T\n",
    "            corr_df = pd.concat([corr_df, first_row_df], ignore_index=True)\n",
    "    return corr_df\n",
    "\n",
    "# Calculate correlations for \"AI\" column\n",
    "df_101112_10day_corr = calculate_correlations(df_101112, df_101112_10day_corr, 10)\n",
    "\n",
    "# 空值補0\n",
    "df_101112_10day_corr = df_101112_10day_corr.fillna(0)\n",
    "\n",
    "# Drop \"漲跌幅\" column\n",
    "df_101112_10day_corr = df_101112_10day_corr.drop(columns=['漲跌幅'], errors='ignore')\n",
    "\n",
    "# Save the result to a CSV file\n",
    "df_101112_10day_corr.to_csv('/Users/lomingyi/Documents/NTU/ccClub/期末專案/00850/df_101112_10day_corr.csv', index=False)\n",
    "\n",
    "# Display the result\n",
    "print(df_101112_10day_corr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
